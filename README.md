# ‚õàÔ∏è Pipeline de Engenharia de Dados: Monitoramento Clim√°tico Regional

> **Projeto inspirado no curso da Udemy: Projeto Real de Engenharia de Dados: Real Time Analytics**
---

## üìñ Sobre o Projeto

Este reposit√≥rio documenta a implementa√ß√£o de um pipeline **ETL (Extract, Transform, Load)** completo para monitoramento de condi√ß√µes meteorol√≥gicas cr√≠ticas em tempo real.

O objetivo central foi replicar a l√≥gica de neg√≥cios de uma arquitetura corporativa de Big Data, por√©m adaptando-a para um cen√°rio de **custo zero** e infraestrutura ef√™mera, demonstrando capacidade de abstra√ß√£o e engenharia de software.

Veja como ficou o resultado final: https://lookerstudio.google.com/reporting/5ee24cf9-af6c-4350-a7c9-bab3ef5927ed

---

## üèóÔ∏è Arquitetura: Da Nuvem Enterprise para a Solu√ß√£o "Smart"

A base te√≥rica deste projeto vem de uma arquitetura cl√°ssica de Streaming na AWS. O desafio foi substituir componentes pagos por solu√ß√µes eficientes em c√≥digo Python.

### 1. O Modelo Original (AWS Enterprise)
Baseado na arquitetura de refer√™ncia corporativa, o fluxo original utilizava recursos com cobran√ßa por hora/disponibilidade:
* **Ingest√£o:** `API Gateway` + `Lambda Producer`
* **Broker de Mensagens:** `Amazon Kinesis Data Streams` (Custo fixo alto por shard)
* **Processamento:** `Lambda Consumer` + `Glue Jobs` (Cobran√ßa por DPU)
* **Cat√°logo:** `AWS Glue Data Catalog`
* **Orquestra√ß√£o:** `CloudWatch Events`

### 2. A Solu√ß√£o Implementada (Serverless)
Refatorei a arquitetura mantendo os princ√≠pios de Engenharia de Dados (Desacoplamento, Resili√™ncia e Idempot√™ncia), mas alterando a tecnologia para custo zero:

| Fun√ß√£o | Componente AWS (Original) | Solu√ß√£o "Github Codespace e Google Looker" (Atual) |
| :--- | :--- | :--- |
| **Gatilho** | CloudWatch Events | Execu√ß√£o Manual / Cron no Container |
| **Extra√ß√£o** | Lambda Producer | Script Python (`requests`) |
| **Broker** | Kinesis Data Streams | Vari√°veis em Mem√≥ria (Python Lists) |
| **Transforma√ß√£o**| Glue / Lambda Consumer | Biblioteca `pandas` (Dataframes) |
| **Storage** | Amazon S3 | **Git** (Versionamento de CSV) |
| **Analytics** | Amazon Athena / QuickSight | **Google Sheets** + **Looker Studio** |

---

## üõ†Ô∏è Tecnologias Utilizadas
* **Linguagem:** Python 3.12
* **Bibliotecas:** `pandas`, `requests`, `python-dotenv`
* **Fonte de Dados:** Tomorrow.io API
* **Orquestra√ß√£o:** Script Python Modular (`main.py`)
* **Visualiza√ß√£o:** Google Sheets e Google Looker Studio

## Como Executar

### Pr√©-requisitos
* Conta no GitHub (Gratuita)
* API Key da Tomorrow.io (Gratuita)
* Planilha no Google Sheets (Gratuita)
* Criar relat√≥rio no Googler Looker Studio (Gratuito)


### Passo a Passo
1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/](https://github.com/)[SEU_USUARIO]/[NOME_DO_REPO].git
    cd [NOME_DO_REPO]
    ```

2.  **Configure o Ambiente Virtual:**
    ```bash
    touch .env #Cria o arquivo .env na raiz do projeto
    python -m venv venv
    source venv/bin/activate #Ativa o ambiente virtual
    ```

3.  **Baixe os requirements:**
    ```bash
    cd ./projeto-clima-etl/
    pip install -r requirements.txt
    ```

4.  **Configurando API e Localiza√ß√£o:**
    ```text
    TOMORROW_API_KEY= Gerar a api no Tomorrow https://app.tomorrow.io/home
    LOCATION=-23.5505, -46.6333 (Meu exemplo)
    ```

5. **Executando o pipeline:**
    ```bash
        python main.py
    ```

6. **Suba o CSV gerado para o Github:**
    ```bash
        git add .
        git commit -m "Sua mensagem de commit"
        git push
    ```

## üìà Configura√ß√£o do Sheets

1. **No Sheets crie uma planilha vazia (em branco)**
* **Obs: Voc√™ precisar√° que o .csv esteja na pasta gold do reposit√≥rio do Github**
2. **Navegue at√© a pasta onde est√° o .csv e clique nele apenas para visualiza√ß√£o**
3. **Ser√° exibido o .csv por√©m no canto direito superior haver√° uma op√ß√£o chamada "raw" clique nela e copie o link com final csv**
4. **Na c√©lula A1 clique duas vezes e adicione =IMPORTDATA("Colar o link do CSV")**
5. **Mude para Estados Unidos**
* **Por que? O Python gera n√∫meros com ponto (25.5). O Sheets Brasil espera v√≠rgula. Mudar para EUA corrige a leitura dos dados.**
7. **Acesse o Google Looker Studio.** <br>

## üìä Configura√ß√£o do Looker

8. **Crie um relat√≥rio vazio.**
9. **Selecione a fonte de dados Planilhas Google.**
10. **Escolha a planilha que voc√™ criou.**
11. **Pronto! Seus gr√°ficos ser√£o atualizados sempre que voc√™ rodar o script Python e atualizar a planilha.**

---
*Desenvolvido por: @Guilherme-Soares05 como projeto de Portf√≥lio de Engenharia de Dados.*